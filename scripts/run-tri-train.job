#!/bin/bash
  
#SBATCH -p compute       # which partition to run on
#SBATCH --gres=gpu:rtx2080ti:1
#SBATCH -J %(name)s    # name for the job
#SBATCH -d singleton
#SBATCH --mem=18000
#SBATCH --cpus-per-task=6
#SBATCH --ntasks=1
#SBATCH -N 1-1

source ${HOME}/tri-training/mtb-tri-training/config/locations.sh

SCRIPTDIR=${PRJ_DIR}/scripts
WORKDIR=${PRJ_DIR}/workdirs/%(name)s

#export PYTHONUNBUFFERED=x

mkdir -p ${WORKDIR}

cd ${WORKDIR}
touch run.start
echo $(hostname) $(date) >> run.start
if [ -e run.end ]; then
    mv run.end run.prev-end
fi

cd ${SCRIPTDIR}
./tri-train.py   \
    --init-seed %(seed)s       \
    %(more_options)s   \
    %(ovs_options)s    \
    %(wrpl_options)s   \
    %(disa_options)s   \
    %(decay_options)s  \
    --model-module %(model_module)s  \
    --subset-size "%(subsetsize)dk"          \
    --augment-size %(augsize)dk   \
    --deadline 36.0            \
    --stopfile ${WORKDIR}/stop  \
    --model-init compose  \
    --unlabelled %(lcode)s_wp17    \
    --unlabelled %(lcode)s_cc17    \
    --labelled   %(tbid)s  \
    --final-test          \
    --continue             \
    --epoch-selection last  \
    --iterations %(iterations)d  \
    --workdir ${WORKDIR}     \
    2> ${WORKDIR}/stderr.txt  \
    >  ${WORKDIR}/stdout.txt

touch ${WORKDIR}/run.end

