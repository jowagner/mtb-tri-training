#!/bin/bash
  
#SBATCH -p compute       # which partition to run on
#SBATCH --gres=gpu:%(gpu_name)s:1
#SBATCH -J %(name)s    # name for the job
#SBATCH -d singleton
#SBATCH --mem=18000
#SBATCH --cpus-per-task=4
#SBATCH --ntasks=1
#SBATCH -N 1-1

source ${HOME}/tri-training/mtb-tri-training/config/locations.sh

SCRIPTDIR=${PRJ_DIR}/scripts
WORKDIR=${PRJ_DIR}/workdirs/%(name)s

#export PYTHONUNBUFFERED=x

mkdir -p ${WORKDIR}

cd ${WORKDIR}
touch run.start
echo $(hostname) $(date) >> run.start
if [ -e run.end ]; then
    mv run.end previous-run.end
fi
if [ -e stderr.txt ]; then
    mv stderr.txt previous-stderr.txt
fi
if [ -e stdout.txt ]; then
    mv stdout.txt previous-stdout.txt
fi

rm -rf stop *workdir

cd ${SCRIPTDIR}
./tri-train.py   \
    --opt-max-subsets 1  \
    --init-seed %(seed)s       \
    %(lang_options)s   \
    %(more_options)s   \
    %(ovs_options)s    \
    %(wrpl_options)s   \
    %(disa_options)s   \
    %(decay_options)s  \
    --model-module %(model_module)s  \
    %(model_keyword_options)s           \
    --subset-size "%(subsetsize)dk"          \
    --subset-stratified                      \
    --augment-size %(augsize)dk   \
    --deadline 18.0            \
    --stopfile ${WORKDIR}/stop  \
    --model-init compose  \
    --unlabelled %(lcode)s_wp17    \
    --unlabelled %(lcode)s_cc17    \
    --subset-filter-keyword max_token_bytes 200  \
    --labelled   %(tbid)s  \
    --final-test          \
    --continue             \
    --tolerant              \
    --rename-dispensable    \
    --epoch-selection last  \
    --iterations %(iterations)d  \
    --workdir ${WORKDIR}     \
    2> ${WORKDIR}/stderr.txt  \
    >  ${WORKDIR}/stdout.txt

touch ${WORKDIR}/run.end

